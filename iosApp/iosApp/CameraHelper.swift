import Foundation
import AVFoundation
import Vision
import UIKit
import CoreImage

/// ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ëŸ¬ ë° í…ìŠ¤íŠ¸ ì¸ì‹
@objc(CameraHelper)
public class CameraHelper: NSObject {
    
    // MARK: - Singleton
    @objc public static let shared = CameraHelper()
    
    private var captureSession: AVCaptureSession?
    private var photoOutput: AVCapturePhotoOutput?
    private var videoOutput: AVCaptureVideoDataOutput?
    private var previewLayer: AVCaptureVideoPreviewLayer?
    private let sessionQueue = DispatchQueue(label: "com.parkingpass.camera.session.queue")
    // PhotoCaptureDelegateë¥¼ ê°•í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•œ ì„ì‹œ ì €ì¥ì†Œ
    private var currentPhotoCaptureDelegate: PhotoCaptureDelegate?
    // VideoOutputDelegateë¥¼ ê°•í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•œ ì €ì¥ì†Œ
    private var videoOutputDelegate: VideoOutputDelegate?
    // ë¹„ë””ì˜¤ í”„ë ˆì„ ì½œë°±
    private var videoFrameCallback: ((Data?) -> Void)?
    // í”„ë ˆì„ ìŠ¤ë¡œí‹€ë§ì„ ìœ„í•œ ë³€ìˆ˜
    private var lastFrameProcessedTime: TimeInterval = 0
    private let frameProcessingInterval: TimeInterval = 0.33 // ì´ˆë‹¹ ì•½ 3í”„ë ˆì„
    // CIContext ì¬ì‚¬ìš©ì„ ìœ„í•œ í”„ë¡œí¼í‹° (ë§¤ í”„ë ˆì„ë§ˆë‹¤ ìƒì„±í•˜ì§€ ì•Šë„ë¡)
    private let ciContext = CIContext()
    
    // MARK: - Permission
    
    /// ì¹´ë©”ë¼ ê¶Œí•œ ìƒíƒœ í™•ì¸
    @objc public static func hasPermission() -> Bool {
        return AVCaptureDevice.authorizationStatus(for: .video) == .authorized
    }
    
    /// ì¹´ë©”ë¼ ê¶Œí•œ ìš”ì²­
    @objc(requestPermissionWithCompletion:) public static func requestPermission(completion: @escaping (Bool) -> Void) {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            completion(true)
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { granted in
                DispatchQueue.main.async {
                    completion(granted)
                }
            }
        default:
            completion(false)
        }
    }
    
    // MARK: - Camera Setup
    
    /// ì¹´ë©”ë¼ ì„¸ì…˜ ì„¤ì • ë° PreviewView ë°˜í™˜
    @objc(setupCameraWithCompletion:) public func setupCamera(completion: @escaping (PreviewView?) -> Void) {
        NSLog("setupCamera called")
        // ì„¸ì…˜ íì—ì„œ ëª¨ë“  ì‘ì—… ìˆ˜í–‰
        sessionQueue.async { [weak self] in
            guard let self = self else {
                DispatchQueue.main.async {
                    completion(nil)
                }
                return
            }
            
            // ê¸°ì¡´ ì„¸ì…˜ì´ ì‹¤í–‰ ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ì§€
            if let existingSession = self.captureSession, existingSession.isRunning {
                NSLog("Stopping existing session before setup")
                existingSession.stopRunning()
            }
            
            // ê¸°ì¡´ ì„¸ì…˜ ì •ë¦¬ (sessionQueueì—ì„œ ì•ˆì „í•˜ê²Œ)
            NSLog("Cleaning up existing session - photoOutput before: \(self.photoOutput != nil), session before: \(self.captureSession != nil)")
            self.captureSession = nil
            self.photoOutput = nil
            NSLog("After cleanup - photoOutput: \(self.photoOutput != nil), session: \(self.captureSession != nil)")
            DispatchQueue.main.async {
                self.previewLayer = nil
            }
            
            let session = AVCaptureSession()
            session.sessionPreset = .photo
            NSLog("Created new AVCaptureSession")
            
            guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
                DispatchQueue.main.async {
                    completion(nil)
                }
                return
            }
            
            do {
                let videoInput = try AVCaptureDeviceInput(device: videoDevice)
                
                // ì„¸ì…˜ ì„¤ì • ì‹œì‘
                session.beginConfiguration()
                
                if session.canAddInput(videoInput) {
                    session.addInput(videoInput)
                } else {
                    session.commitConfiguration()
                    DispatchQueue.main.async {
                        completion(nil)
                    }
                    return
                }
                
                let output = AVCapturePhotoOutput()
                if session.canAddOutput(output) {
                    session.addOutput(output)
                    // photoOutputì„ ì„¸ì…˜ íì—ì„œ ì„¤ì • (ìŠ¤ë ˆë“œ ì•ˆì „)
                    self.photoOutput = output
                    NSLog("photoOutput set: \(self.photoOutput != nil)")
                } else {
                    NSLog("ERROR: cannot add photoOutput to session")
                    // output ì¶”ê°€ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì²˜ë¦¬
                    session.commitConfiguration()
                    DispatchQueue.main.async {
                        completion(nil)
                    }
                    return
                }
                
                // ì„¸ì…˜ ì„¤ì • ì™„ë£Œ
                session.commitConfiguration()
                
                // ì„¸ì…˜ ì €ì¥ ë° photoOutput ì €ì¥ (ì¤‘ìš”: ê°™ì€ sessionQueueì—ì„œ)
                self.captureSession = session
                // photoOutputì€ ì´ë¯¸ ìœ„ì—ì„œ ì„¤ì •ë¨ (line 96)
                
                // photoOutputì´ nilì´ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ í™•ì¸ (sessionQueueì—ì„œ í™•ì¸)
                NSLog("Before guard - photoOutput: \(self.photoOutput != nil)")
                guard let photoOutput = self.photoOutput else {
                    NSLog("ERROR: photoOutput is nil after setting up session!")
                    DispatchQueue.main.async {
                        completion(nil)
                    }
                    return
                }
                NSLog("After guard - photoOutput exists: true")
                let hasCaptureSession = self.captureSession != nil
                NSLog("Before startRunning - photoOutput exists: \(photoOutput != nil), captureSession exists: \(hasCaptureSession)")
                
                // ì„¸ì…˜ ì‹œì‘ (sessionQueueì—ì„œ - ë¸”ë¡œí‚¹ í˜¸ì¶œì´ë¯€ë¡œ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°)
                session.startRunning()
                
                let hasSessionAfterStart = self.captureSession != nil
                NSLog("After startRunning - photoOutput exists: \(self.photoOutput != nil), captureSession exists: \(hasSessionAfterStart), isRunning: \(session.isRunning)")
                
                // PreviewView ìƒì„± ë° ì„¸ì…˜ ì„¤ì • (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ - Apple ê¶Œì¥ì‚¬í•­)
                DispatchQueue.main.async { [weak self] in
                    guard let self = self else {
                        completion(nil)
                        return
                    }
                    let previewView = PreviewView()
                    previewView.backgroundColor = .black
                    if let previewLayer = previewView.previewLayer {
                        previewLayer.session = session
                        previewLayer.videoGravity = .resizeAspectFill
                        self.previewLayer = previewLayer
                    }
                    NSLog("Camera setup completed - photoOutput: \(self.photoOutput != nil), captureSession: \(self.captureSession != nil)")
                    completion(previewView)
                }
            } catch {
                DispatchQueue.main.async {
                    completion(nil)
                }
            }
        }
    }
    
    /// ì¹´ë©”ë¼ ì„¸ì…˜ ì¤‘ì§€
    @objc public func stopCamera() {
        NSLog("stopCamera called")
        stopVideoAnalysis()
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            NSLog("stopCamera executing - photoOutput before: \(self.photoOutput != nil), session before: \(self.captureSession != nil)")
            self.captureSession?.stopRunning()
            self.captureSession = nil
            self.photoOutput = nil
            self.videoOutput = nil
            NSLog("stopCamera executed - photoOutput after: \(self.photoOutput != nil)")
            DispatchQueue.main.async {
                self.previewLayer = nil
            }
        }
    }
    
    // MARK: - Capture Image
    
    /// ì‚¬ì§„ ì´¬ì˜
    @objc(capturePhotoWithCompletion:) public func capturePhoto(completion: @escaping (Data?, Error?) -> Void) {
        sessionQueue.async { [weak self] in
            guard let self = self else {
                NSLog("ERROR: CameraHelper is nil in capturePhoto")
                DispatchQueue.main.async {
                    completion(nil, NSError(domain: "CameraHelper", code: -1, userInfo: [NSLocalizedDescriptionKey: "CameraHelper is nil"]))
                }
                return
            }
            
            NSLog("capturePhoto called - photoOutput: \(self.photoOutput != nil), session: \(self.captureSession != nil), isRunning: \(self.captureSession?.isRunning ?? false)")
            
            // photoOutputì„ ë¨¼ì € í™•ì¸ (sessionQueueì—ì„œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼)
            let photoOutput = self.photoOutput
            guard let output = photoOutput else {
                NSLog("ERROR: photoOutput is nil in capturePhoto")
                DispatchQueue.main.async {
                    completion(nil, NSError(domain: "CameraHelper", code: -1, userInfo: [NSLocalizedDescriptionKey: "Photo output not available"]))
                }
                return
            }
            
            guard let captureSession = self.captureSession, captureSession.isRunning else {
                NSLog("ERROR: Capture session is not running in capturePhoto")
                DispatchQueue.main.async {
                    completion(nil, NSError(domain: "CameraHelper", code: -2, userInfo: [NSLocalizedDescriptionKey: "Capture session is not running"]))
                }
                return
            }
            
            // PhotoCaptureDelegateë¥¼ strong referenceë¡œ ìœ ì§€í•˜ê¸° ìœ„í•´ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
            // (delegateê°€ ì™„ë£Œë˜ê¸° ì „ì— í•´ì œë˜ì§€ ì•Šë„ë¡)
            let delegate = PhotoCaptureDelegate { [weak self] imageData, error in
                // completion í˜¸ì¶œ í›„ delegate í•´ì œ
                completion(imageData, error)
                DispatchQueue.main.async {
                    self?.currentPhotoCaptureDelegate = nil
                }
            }
            // ê°•í•œ ì°¸ì¡° ìœ ì§€ë¥¼ ìœ„í•´ ì„ì‹œë¡œ ì €ì¥ (completionì´ í˜¸ì¶œë  ë•Œê¹Œì§€ ìœ ì§€ë¨)
            self.currentPhotoCaptureDelegate = delegate
            
            let settings = AVCapturePhotoSettings()
            NSLog("ğŸ“¸ [CameraHelper] capturePhoto í˜¸ì¶œ - settings ìƒì„± ì™„ë£Œ")
            output.capturePhoto(with: settings, delegate: delegate)
            NSLog("ğŸ“¸ [CameraHelper] capturePhoto í˜¸ì¶œ ì™„ë£Œ - delegate ì„¤ì •ë¨")
        }
    }
    
    // MARK: - Video Analysis
    
    /// ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ í”„ë ˆì„ ë¶„ì„ ì‹œì‘
    @objc(startVideoAnalysisWithCallback:) public func startVideoAnalysis(callback: @escaping (Data?) -> Void) {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            self.videoFrameCallback = callback
            
            // ê¸°ì¡´ videoOutputì´ ìˆìœ¼ë©´ ì œê±°
            if let existingVideoOutput = self.videoOutput,
               let session = self.captureSession,
               session.outputs.contains(existingVideoOutput) {
                session.beginConfiguration()
                session.removeOutput(existingVideoOutput)
                session.commitConfiguration()
            }
            
            guard let session = self.captureSession else {
                NSLog("ERROR: Capture session is nil in startVideoAnalysis")
                return
            }
            
            let videoOutput = AVCaptureVideoDataOutput()
            videoOutput.videoSettings = [
                kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA)
            ]
            
            let delegate = VideoOutputDelegate { [weak self] sampleBuffer in
                guard let self = self,
                      let callback = self.videoFrameCallback else { return }
                
                // í”„ë ˆì„ ìŠ¤ë¡œí‹€ë§ (ì´ˆë‹¹ ì•½ 3í”„ë ˆì„ë§Œ ì²˜ë¦¬)
                let currentTime = CACurrentMediaTime()
                guard currentTime - self.lastFrameProcessedTime >= self.frameProcessingInterval else { return }
                self.lastFrameProcessedTime = currentTime
                
                // CMSampleBufferë¥¼ UIImageë¡œ ë³€í™˜
                guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
                    callback(nil)
                    return
                }
                
                let ciImage = CIImage(cvPixelBuffer: imageBuffer)
                guard let cgImage = self.ciContext.createCGImage(ciImage, from: ciImage.extent) else {
                    callback(nil)
                    return
                }
                
                let uiImage = UIImage(cgImage: cgImage)
                
                // UIImageë¥¼ JPEG Dataë¡œ ë³€í™˜ (ì‹¤ì‹œê°„ ì²˜ë¦¬ì— ì í•©í•œ ë‚®ì€ ì••ì¶• í’ˆì§ˆ ì‚¬ìš©)
                guard let jpegData = uiImage.jpegData(compressionQuality: 0.6) else {
                    callback(nil)
                    return
                }
                
                // ì½œë°± í˜¸ì¶œ (ë©”ì¸ ìŠ¤ë ˆë“œê°€ ì•„ë‹Œ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œ)
                callback(jpegData)
            }
            
            videoOutput.setSampleBufferDelegate(delegate, queue: self.sessionQueue)
            
            session.beginConfiguration()
            if session.canAddOutput(videoOutput) {
                session.addOutput(videoOutput)
                self.videoOutput = videoOutput
                self.videoOutputDelegate = delegate
                NSLog("Video output added successfully")
            } else {
                NSLog("ERROR: Cannot add video output to session")
            }
            session.commitConfiguration()
        }
    }
    
    /// ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ í”„ë ˆì„ ë¶„ì„ ì¤‘ì§€
    @objc public func stopVideoAnalysis() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            if let videoOutput = self.videoOutput,
               let session = self.captureSession,
               session.outputs.contains(videoOutput) {
                session.beginConfiguration()
                session.removeOutput(videoOutput)
                session.commitConfiguration()
            }
            
            self.videoOutput?.setSampleBufferDelegate(nil, queue: nil)
            self.videoOutput = nil
            self.videoOutputDelegate = nil
            self.videoFrameCallback = nil
            self.lastFrameProcessedTime = 0 // í”„ë ˆì„ ìŠ¤ë¡œí‹€ë§ ë³€ìˆ˜ ì´ˆê¸°í™”
        }
    }
    
    // MARK: - Text Recognition
    
    /// ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¸ì‹
    @objc(recognizeTextWithImageData:completion:) public static func recognizeText(_ imageData: Data, completion: @escaping (String?, Float, Error?) -> Void) {
        // ë°±ê·¸ë¼ìš´ë“œ íì—ì„œ ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ì—¬ UI ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ ë°©ì§€
        DispatchQueue.global(qos: .userInitiated).async {
            guard let image = UIImage(data: imageData) else {
                DispatchQueue.main.async {
                    completion(nil, 0, NSError(domain: "CameraHelper", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to create image"]))
                }
                return
            }
            
            guard let cgImage = image.cgImage else {
                DispatchQueue.main.async {
                    completion(nil, 0, NSError(domain: "CameraHelper", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to get CGImage"]))
                }
                return
            }
            
            let request = VNRecognizeTextRequest { request, error in
                if let error = error {
                    DispatchQueue.main.async {
                        completion(nil, 0, error)
                    }
                    return
                }
                
                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                    DispatchQueue.main.async {
                        completion(nil, 0, NSError(domain: "CameraHelper", code: -1, userInfo: [NSLocalizedDescriptionKey: "No text found"]))
                    }
                    return
                }
                
                var recognizedStrings: [String] = []
                var maxConfidence: Float = 0
                
                for observation in observations {
                    guard let topCandidate = observation.topCandidates(1).first else { continue }
                    recognizedStrings.append(topCandidate.string)
                    maxConfidence = max(maxConfidence, topCandidate.confidence)
                }
                
                let fullText = recognizedStrings.joined(separator: " ")
                DispatchQueue.main.async {
                    completion(fullText, maxConfidence, nil)
                }
            }
            
            request.recognitionLanguages = ["ko-KR", "en-US"]
            request.recognitionLevel = .accurate
            
            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            do {
                try handler.perform([request])
            } catch {
                DispatchQueue.main.async {
                    completion(nil, 0, error)
                }
            }
        }
    }
}

// MARK: - PreviewView

/// AVCaptureVideoPreviewLayerë¥¼ layerë¡œ ì‚¬ìš©í•˜ëŠ” UIView
@objc(PreviewView)
public class PreviewView: UIView {
    public override class var layerClass: AnyClass {
        return AVCaptureVideoPreviewLayer.self
    }
    
    public var previewLayer: AVCaptureVideoPreviewLayer? {
        return layer as? AVCaptureVideoPreviewLayer
    }
}

// MARK: - Video Output Delegate

private class VideoOutputDelegate: NSObject, AVCaptureVideoDataOutputSampleBufferDelegate {
    private let onFrame: (CMSampleBuffer) -> Void
    
    init(onFrame: @escaping (CMSampleBuffer) -> Void) {
        self.onFrame = onFrame
        super.init()
    }
    
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        onFrame(sampleBuffer)
    }
}

// MARK: - Photo Capture Delegate

private class PhotoCaptureDelegate: NSObject, AVCapturePhotoCaptureDelegate {
    private let completion: (Data?, Error?) -> Void
    
    init(completion: @escaping (Data?, Error?) -> Void) {
        self.completion = completion
        super.init()
        NSLog("ğŸ“¸ [PhotoCaptureDelegate] ì´ˆê¸°í™”")
    }
    
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        NSLog("ğŸ“¸ [PhotoCaptureDelegate] didFinishProcessingPhoto í˜¸ì¶œë¨ - error: \(error?.localizedDescription ?? "nil")")
        
        if let error = error {
            NSLog("âŒ [PhotoCaptureDelegate] ì—ëŸ¬ ë°œìƒ: \(error.localizedDescription)")
            DispatchQueue.main.async { [completion] in
                completion(nil, error)
            }
            return
        }
        
        guard let imageData = photo.fileDataRepresentation() else {
            NSLog("âŒ [PhotoCaptureDelegate] ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
            DispatchQueue.main.async { [completion] in
                completion(nil, NSError(domain: "PhotoCaptureDelegate", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to get image data"]))
            }
            return
        }
        
        NSLog("âœ… [PhotoCaptureDelegate] ì´ë¯¸ì§€ ë°ì´í„° ì„±ê³µ - í¬ê¸°: \(imageData.count) bytes")
        DispatchQueue.main.async { [completion] in
            completion(imageData, nil)
        }
    }
}

